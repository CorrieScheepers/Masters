\chapter{Conclusion}
\label{chap:4}
\ChapterPageStuff{4}

\section{Discussion}

\subsection{Contributions made to literature}
\Cref{chap:1} highlighted the importance of software maintenance in the entire life cycle of most software systems. The following gap in the literature was identified in \Cref{sec:ch1_gapIdentification} from the obtained studies about software maintenance: 

\begin{center}
	\begin{tcolorbox}[colback=lightgray, colframe=black, sharp corners=all, arc=4pt]
		\begin{minipage}{\textwidth}
			\RaggedRight\textit{\studyGap}
		\end{minipage}
	\end{tcolorbox}
\end{center}

Using event logging to create a log analysis for utilising the software systems is a possible solution to make software maintenance prioritisations. A State Of The Art analysis in \Cref{tbl:ch1_stateOfTheArt2} for the literature of software maintenance, event logging and log analysis was made. This study will be referred to as \textit{Study U}, filling the gaps in the obtained literature with the method in \Cref{chap:2} that is included in the updated State of The Art in \Cref{tbl:ch4_stateOfTheArt}.

\begin{table}[!htb]
	\centering
	\caption[State Of The Art]
	{\textit{State Of The Art}}
	\label{tbl:ch4_stateOfTheArt}
	\begin{threeparttable}
		\begin{tabularx}{\textwidth}{cYYYYYY}
			\toprule
			\thead{Ref.} & \multicolumn{3}{c}{\thead{Software maintenance}} & \multicolumn{2}{c}{\thead{Event logging}} & \multicolumn{1}{c}{\thead{Log analysis}} \\ 
			 \cmidrule(lr){2-4} \cmidrule(lr){5-6} \cmidrule(lr){7-7}
			 & \RaggedRight \thead{Models} & \RaggedRight \thead{Problems} & \RaggedRight \thead{Prioritisation} & \thead{Parsing} & \thead{Points} & \RaggedRight \thead{Utilisation} \\ 		
			\midrule
				\sotaCore
				\rowcolor{pastelgreen}
				\textit{U}\tnote{$\ast$} & Partial & \cmark & \cmark & \cmark & \cmark & \cmark \\
			\bottomrule
		\end{tabularx}
		\begin{tablenotes}\footnotesize
			\item[$\ast$] \textit{Study U:~\ThesisTitle}
		\end{tablenotes}
	\end{threeparttable}
\end{table}

\Cref{tbl:ch4_stateOfTheArt} there is a divide between the software maintenance, event logging and log analysis in the State Of The Art. \textit{Study U} can contribute to the literature by providing a comprehensive method that includes all three of these main research topics. \par Event logging and log analysis overlap more in literature than software maintenance as a primary topic. It was identified that the research on software maintenance could be limited by no third-party validation, not always attempting to improve or build on existing software maintenance models, little comparison with other literature and difficulty replicating due to private data sets or custom tools.\par The obtained studies that discussed software maintenance commonly identified that the efficiency of implementing software maintenance is essential. Some studies attempted to use specific software maintenance models on certain software maintenance types for better efficiency. \par Other studies tried to create task distribution for developers to improve software maintenance efficiency. Other studies attempted to isolate certain software maintenance resource costs in the entire Software Development Life-Cycle (SDLC).\par Additionally, these studies didn't try to provide the needed method to prioritise these software systems. The method needs to use a logging mechanism to do the log analysis, which is not present in software maintenance-related studies.\par \textit{Study U} does not explicitly use any software maintenance models as it is irrelevant to the prioritisation of the software systems. For this reason, the model's State Of The Art topic is marked as partially achieved. From the software maintenance problems identified in the literature, the requirements for the log analysis are created for the software maintenance prioritisation. \par The methods for the event logging mechanisms are not fully described or uses third-party tools. Software maintenance does not overlap with this topic, as most event logging is for system diagnostics.\par There were logging mechanisms that captured user-based logs. The purpose of those obtained logs is mainly used for user-behavioural analysis instead of system utilisation analysis. \textit{Study U} contributes to the literature on the system utilisation analysis for software maintenance when prioritised.

\subsection{Value added to industry}
The method in \Cref{chap:2} is used on different case studies in \Cref{sec:ch3_caseStudies}. Each of these case studies explored the various applications of the generic logging mechanism to obtain user-based events. The results proved that the logging mechanism could get the desired user-based activities. However, additional adaptations were needed for each case study to ensure that log quality was acceptable for consistent and reliable log analysis.\par These adaptations were due to the software environment (software languages and design methodologies used) and the purpose of the software system. Older systems had to use different logging points to yield the same result as newer software systems that can use less or one logging point.\par These systems used the same user-based event type with similar operational software use cases. Systems with the same software architecture but different functional use cases also had various adaptations to their logging mechanism. These adaptations ensured that the desired log attributes were correctly obtained for the log analysis. \par The maintenance prioritisation recommendations for each study case used the defined generic methodology. The log analysis for each case study was similar as the log requirements for the user-based utilisation for all the case studies were only different for each of their user-based event types. These user-based event types represent the operational use cases for the case study to further observe the kind of utilisation of the subsystems. \par The results proved that the generic methodology defined in \Cref{chap:2} could be implemented on different software systems with other operational use cases for each case study. In the web development industry, similar software systems as the case study or other software systems will benefit from implementing this methodology to improve software maintenance decisions using these recommendations for prioritisation.

\subsection{Validation strategy}
The following validation strategy is used for this study:

\begin{enumerate}[label=\textbf{\Roman*.}]
	\item Revisit the literature gap defined in \Cref{sec:ch1_gapIdentification}.
	\item Revisit the original problem statement defined in \Cref{sec:ch1_problemStatement}.
	\item Revisit the study objectives defined in \Cref{sec:ch1_objectives}.
	\item Reflect on the results and results of the study methodology in \Cref{chap:3}.
	\item Determine whether a solution has been presented to the original problem statement. 
\end{enumerate}

Using the research objectives in \Cref{sec:ch1_literatureObjective} for this study have been met in \Cref{tbl:ch4_ValidationStart}. 

\begin{xltabular}{\textwidth}{cXp{3cm}c}
	\caption[Study validation]
	{\textit{Study validation}}
	\label{tbl:ch4_ValidationStart} \\

	\toprule
	\thead{Objective ID} & \thead{Objective}  & \thead{Section} & \thead{Objective met} \\ 
	\midrule
	\endfirsthead

	\multicolumn{4}{c}
	{\tablename\ \thetable{} -- continued from previous page} \\
	\midrule
	\thead{Objective ID} & \thead{Objective}  & \thead{Section} & \thead{Objective met} \\
	\midrule
	\endhead

	\midrule
	\multicolumn{4}{r}{{Continued on next page}} \\ \midrule
	\endfoot
	\endlastfoot

	\multicolumn{4}{l}{\thead{Literature Objectives:}} \\ 
	\midrule
	\rowcolor{lightgray}
	L1 & \RaggedRight \objAi & \RaggedRight \Cref{sec:ch2_logAttributesRequirements,sec:ch2_webApplicationArchitecture} & \cmark \\
	L2 & \RaggedRight \objAii & \RaggedRight \Cref{sec:ch2_loggingPoints,sec:ch2_webApplicationArchitecture} & \cmark \\
	\rowcolor{lightgray}
	L3 & \RaggedRight \objAiii & \Cref{sec:ch2_logAnalysisTools} & \cmark \\ 
	L4 & \RaggedRight \objAiv & \Cref{sec:ch2_utilisationImprovements} & \cmark \\ 
	\midrule
	\multicolumn{4}{l}{\thead{Empirical Objectives:}} \\ 
	\midrule
	\rowcolor{lightgray}
	E1 & \RaggedRight \objBi: 
		\begin{enumerate}
			\item \objBiSubA
			\item \objBiSubB
			\item \objBiSubC
			\item \objBiSubD
		\end{enumerate} & \Cref{sec:ch3_implementation} & \cmark \\
	E2 & \RaggedRight \objBii & \Cref{sec:ch3_Verification} & \cmark \\
	\rowcolor{lightgray}
	E3 & \RaggedRight \objBiii & \Cref{sec:ch3_caseStudies} & \cmark \\
	\bottomrule
\end{xltabular}

\Cref{tbl:ch4_ValidationStart} shows the literature objectives in \Cref{chap:2} by implementing the development of the solution. Objective L1 The characteristics of the event log are defined with the expected log attributes needed for the log analysis. The event-log characteristics focus on only obtaining user-based event logs with the necessary qualities the logging point can capture and store.\par For objective L2, each user-based event's log attributes must be obtained from the software system using a logging point. The logging points are placed strategically in the software system where it has little impact on the performance of the software system. Requirements for the event logs are created to guide developers in making the logging points to capture the event logs.\par For objective L3, the log quality is essential for the log analysis. This objective ensures that the captured event logs are complete, accurate and available when the logs are extracted by the log analysis tool. The method's requirements were defined to adhere to the log quality specification.\par For objective L4, the maintenance prioritisation is determined. The needed calculations for this log analysis are explained for this objective that needs to be executed in the log analysis. The prioritisation of each subsystem will be calculated in the specified time frame. The requirements for which logs to use are also defined for this objective, as some user activity types can be excluded based on the software system used.\par The empirical objectives use the method on a test system to verify the results and implement it in case studies. It also reflects on the study methodology using the results to determine whether this solution has resolved the problem statement.\par For objective E1, the following sub-objectives are met for the implementation of the method on the test system:

\begin{enumerate}
	\item The user activity types and log attributes for the test system were defined. A logging point(s) was placed on the client or server side for the test system.
	\item This strategic placement of the logging point(s) was determined by what log attributes need to be obtained in certain stages of the software system's logging mechanism, structure and complexity. The logging points store the event logs in a structured database.
	\item A log analysis tool is either created or a suitable third-party tool is used to analyse the extracted logs. Log quality is also checked in this objective to determine if the logs are on an acceptable standard set by the requirements in L3. 
	\item The maintenance prioritisation is calculated for each subsystem for this sub-objective using L4.
\end{enumerate} 

For objective E2, the results of implementing the method on the test system are verified in this objective. Objectives L1, L2, L3 and L4 verified if the method can create software maintenance prioritisations for the test system by comparing it to the expected results. \par For objective E3, the verified method of E1 is applied to multiple case studies, and the results are evaluated. A critical analysis of the case studies is made to validate the software maintenance prioritisation for this study with the results of the case studies. With this validation strategy, this study is validated that it meets the study objectives with the created solution for the original problem statement.

\section{Recommendations}
In \Cref{sec:ch3_caseStudies}, the case studies highlighted the method's limitations. 

\subsection{Logging quality}
\Cref{sec:ch1_loggingQuality} describes the event log quality as an essential part of the logging mechanism. The event logs must be accurate, manage complex structures, and be consistent and complete. For the methodology used, not all of the dimensions of \Cref{fig:ch1_EventQModel} are used to design the logging mechanism.\par This presents Case Study B's logging points functional requirement (\ref{fr:loggingPoints}). The multiple logging points introduced inconsistencies in the event logs for the groups of subsystems used. There are studies on improving event log quality, but creating an event log quality model specifically for user-based event logging can increase the log quality. \par Some of the defined event log quality model requirements specified in \Cref{fig:ch1_EventQModel} still need to be fully integrated into the method. Some of these requirements can add value to the logging quality.

\subsection{Maintenance prioritisation}
The maintenance prioritisation (\ref{fr:maintenancePrioritising}) can have improvements made in multiple ways. \Cref{eq:ch2_maintenanceFactorSimplified,eq:ch2_eventNormalised,eq:ch2_priorityNormalised} uses the full user-based event logs per subsystem and the total users linked per system as its base variables\par From the results observed in the case studies in \Cref{sec:ch3_caseStudies}, the base variables had an overwhelming impact on the prioritisation factor. Introducing other variables that represent other factors from the log attributes can improve the accuracy of maintenance prioritisation. One important variable that could have been used is the user activity type of each case study.

\subsubsection{User activity types}
Throughout the study, the user activity type was essential to describe what can be classified as a user event. This primary log attribute can add another dimension to the results, as some user activities may be more important than others. \par For software systems, as in Case Study C, where most types of user activity were grouped, the final results can be beneficial. There are some differences between some activity types. 

\subsubsection{User and activity parameters}
\par Normalisation is used in \Cref{eq:ch2_maintenanceFactorSimplified,eq:ch2_eventNormalised,eq:ch2_priorityNormalised} to make a comparable scale for both of the main variables for the software maintenance prioritisation. While Normalisation yielded similar results, there were numerous outliers on each variable's low and high ends. The data does not follow a specific distribution or pattern as $S_{582}$ of Case Study A with a normalised activity of 1. This subsystem had the highest normalised activity but the $4^{th}$ highest maintenance priority due to its lower unique active user base.\par Using different techniques to formulate a software maintenance priority factor may have placed $S_{582}$ higher. If the effect of the total unique users were not used as the primary prioritisation factor for this situation. 

\subsubsection{Use of other classification strategies}
Normalisation was used for the maintenance priority calculations. Using other statistical methods can yield improved prioritisation. Only one prioritisation method was used. There is a need to enhance prioritisation by comparing different prioritisation methods.

\clearpage

\section{Conclusion}

\subsection{In summary}
\begin{itemize}
	\item There is a need to improve software maintenance activities in the industry, but software maintenance prioritisation is still a problem for most software developers.
	\item Event-based logging is a proven method to get valuable information about a software system.
	\item A log analysis of the utilisation of the software system can provide the needed evidence to prioritise software systems based on the extracted log data.
	\item Creating a user-based event logging mechanism to implement a system utilisation log analysis solves to the identified problem.
	\item Three different case studies with two other operational use cases verified the designed methodology for this study.
\end{itemize}

\subsection{In conclusion}
Analysing user-based event logs can enhance software maintenance resource management by prioritising maintenance tasks through a comprehensive log analysis.