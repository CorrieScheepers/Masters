\chapter{Conclusion}
\label{chap:4}
\ChapterPageStuff{4}

\section{Discussion}

\subsection{Contributions made to literature}
\Cref{chap:1} highlighted the importance of software maintenance throughout the life cycle of most software systems. A gap in the literature was identified in \Cref{sec:ch1_gapIdentification} from the studies obtained on software maintenance. \par Using event logging to create a log analysis for utilising the software systems is a possible solution to make software maintenance prioritisations. A State Of The Art analysis in \Cref{tbl:ch1_stateOfTheArt2} was made for the literature on software maintenance, event logging, and log analysis. This study will be referred to as \textit{Study U}, filling in the gaps in the literature obtained with the method in \Cref{chap:2} that is included in the updated State of The Art in \Cref{tbl:ch4_stateOfTheArt}.

\begin{table}[!htb]
	\centering
	\caption[State Of The Art]
	{\textit{State Of The Art}}
	\label{tbl:ch4_stateOfTheArt}
	\begin{threeparttable}
		\begin{tabularx}{\textwidth}{cYYYYYY}
			\toprule
			\thead{Ref.} & \multicolumn{3}{c}{\thead{Software maintenance}} & \multicolumn{2}{c}{\thead{Event logging}} & \multicolumn{1}{c}{\thead{Log analysis}} \\ 
			 \cmidrule(lr){2-4} \cmidrule(lr){5-6} \cmidrule(lr){7-7}
			 & \RaggedRight \thead{Models} & \RaggedRight \thead{Problems} & \RaggedRight \thead{Prioritisation} & \thead{Parsing} & \thead{Points} & \RaggedRight \thead{Utilisation} \\ 		
			\midrule
				\sotaCore
				\rowcolor{pastelgreen}
				\textit{U}\tnote{$\ast$} & Partial & \cmark & \cmark & \cmark & \cmark & \cmark \\
			\bottomrule
		\end{tabularx}
		\begin{tablenotes}\footnotesize
			\item[$\ast$] \textit{Study U:~\ThesisTitle}
		\end{tablenotes}
	\end{threeparttable}
\end{table}

\Cref{tbl:ch4_stateOfTheArt} there is a divide between software maintenance, event logging, and log analysis in the State Of The Art. \textit{Study U} can contribute to the literature by providing a comprehensive method that includes all three of these main research topics. \par Event logging and log analysis overlap more in the literature than software maintenance as a primary topic. It was identified that research on software maintenance could be limited by a lack of third-party validation, not always trying to improve or build existing software maintenance models, little comparison with other literature, and difficulty replicating due to private data sets or custom tools.\par The obtained studies that discussed software maintenance commonly identified that the efficiency of implementing software maintenance is essential. Some studies attempted to use specific software maintenance models on certain software maintenance types for better efficiency. \par Other studies tried to create a task distribution for developers to improve software maintenance efficiency. Other studies attempted to isolate certain software maintenance resource costs in the entire Software Development Life-Cycle (SDLC).\par Additionally, these studies did not attempt to provide the method needed to prioritise these software systems. The method needs to use a logging mechanism to do the log analysis, which is not present in software maintenance-related studies.\par \textit{Study U} does not explicitly use any software maintenance models as it is irrelevant to prioritising software systems. For this reason, the model's State Of The Art topic is marked as partially achieved. From the software maintenance problems identified in the literature, the requirements for the log analysis are created for the software maintenance prioritisation. \par The methods for the event logging mechanisms are not fully described or use third-party tools. Software maintenance does not overlap with this topic, as most event logs are for system diagnostics.\par There were logging mechanisms that captured user-based logs. The purpose of those logs obtained is mainly used for user-behavioural analysis instead of system utilisation analysis. \textit{Study U} contributes to the literature on system utilisation analysis for software maintenance when prioritised.

\subsection{Value added to industry}
The method in \Cref{chap:2} is used in different case studies in \Cref{sec:ch3_caseStudies}. Each of these case studies explored the various applications of the generic logging mechanism to obtain user-based events. The results proved that the logging mechanism could get the desired user-based activities. However, additional adaptations were needed for each case study to ensure that log quality was acceptable for consistent and reliable log analysis.\par These adaptations were due to the software environment (software languages and design methodologies used) and the purpose of the software system. Older systems had to use different logging points to produce the same result as newer software systems that can use less or one logging point.\par These systems used the same user-based event type with similar operational software use cases. Systems with the same software architecture but different functional use cases also had various adaptations to their logging mechanism. These adaptations ensured that the desired log attributes were correctly obtained for the log analysis. \par The maintenance prioritisation recommendations for each study case used the defined generic methodology. The log analysis for each case study was similar as the log requirements for the user-based utilisation for all the case studies were only different for each of their user-based event types. These user-based event types represent the operational use cases for the case study to further observe the kind of utilisation of the subsystems. \par The results proved that the generic methodology defined in \Cref{chap:2} could be implemented on different software systems with other operational use cases for each case study. In the web development industry, similar software systems as the case study or other software systems will benefit from implementing this methodology to improve software maintenance decisions using these recommendations for prioritisation.

\subsection{Validation strategy}
The following five-step validation strategy is used for the outcomes of this study:

\begin{enumerate}[label=\textbf{\Roman*.}]
	\item Revisit the literature gap defined in \Cref{sec:ch1_gapIdentification}.
	\item Revisit the original problem statement defined in \Cref{sec:ch1_problemStatement}.
	\item Revisit the study objectives defined in \Cref{sec:ch1_objectives}.
	\item Reflect on the results and results of the study methodology in \Cref{chap:3}.
	\item Determine whether a solution has been presented to the original problem statement. 
\end{enumerate}

This study is validated by:

\begin{enumerate}[label=\textbf{\Roman*.}]
	\item \textbf{Gap in literature} \par The literature gap defined in \Cref{sec:ch1_gapIdentification} for implementing software maintenance efficiently is summarised as: 
		\begin{center}
			\begin{tcolorbox}[colback=lightgray, colframe=black, sharp corners=all, arc=4pt]
				\begin{minipage}{\textwidth}
					\RaggedRight\textit{\studyGap}
				\end{minipage}
			\end{tcolorbox}
		\end{center}

	\item \textbf{Original problem statement} \par The original problem statement defined in \Cref{sec:ch1_problemStatement} to able to make software maintenance priorisations:
		\begin{center}
			\begin{tcolorbox}[colback=lightgray, colframe=black, sharp corners=all, arc=4pt]
				\begin{minipage}{\textwidth}
					\RaggedRight\textit{\problemStatement}
				\end{minipage}
			\end{tcolorbox}
		\end{center}

	\item \textbf{Study objectives} \par Study objectives defined in \Cref{sec:ch1_objectives} that have been met in \Cref{tbl:ch4_ValidationStart} for this study. 

		\begin{xltabular}{\textwidth}{cXp{3cm}c}
			\caption[Study validation]
			{\textit{Study validation}}
			\label{tbl:ch4_ValidationStart} \\

			\toprule
			\thead{Objective ID} & \thead{Objective}  & \thead{Section} & \thead{Objective met} \\ 
			\midrule
			\endfirsthead

			\caption[]{\continueCaption} \\
			\toprule
			\thead{Objective ID} & \thead{Objective}  & \thead{Section} & \thead{Objective met} \\
			\midrule
			\endhead

			\midrule
			\multicolumn{4}{r}{\continueText} \\ \midrule
			\endfoot
			\endlastfoot

			\multicolumn{4}{c}{\thead{Literature Objectives}} \\ 
			\midrule
			\rowcolor{lightgray}
			L1 & \RaggedRight \objAi & \RaggedRight \Cref{sec:ch2_logAttributesRequirements,sec:ch2_webApplicationArchitecture} & \cmark \\
			L2 & \RaggedRight \objAii & \RaggedRight \Cref{sec:ch2_loggingPoints,sec:ch2_webApplicationArchitecture} & \cmark \\
			\rowcolor{lightgray}
			L3 & \RaggedRight \objAiii & \Cref{sec:ch2_logAnalysisTools} & \cmark \\ 
			L4 & \RaggedRight \objAiv & \Cref{sec:ch2_utilisationImprovements} & \cmark \\ 
			\midrule
			\multicolumn{4}{c}{\thead{Empirical Objectives}} \\ 
			\midrule
			\rowcolor{lightgray}
			E1 & \RaggedRight \objBi: 
				\begin{enumerate}
					\item \objBiSubA
					\item \objBiSubB
					\item \objBiSubC
					\item \objBiSubD
				\end{enumerate} & \Cref{sec:ch3_implementation} & \cmark \\
			E2 & \RaggedRight \objBii & \Cref{sec:ch3_Verification} & \cmark \\
			\rowcolor{lightgray}
			E3 & \RaggedRight \objBiii & \Cref{sec:ch3_caseStudies} & \cmark \\
			\bottomrule
		\end{xltabular}

    In \Cref{tbl:ch4_ValidationStart} the objective L1 The characteristics of the event log are defined with the expected log attributes needed for the log analysis. The characteristics of the event log focus only on obtaining user-based event logs with the necessary qualities that the logging point can capture and store.\par For objective L2, the log attributes of each user-based event must be obtained from the software system using a logging point. The logging points are placed strategically in the software system where they have little impact on the performance of the software system. The requirements for the event logs are created to guide developers in making the logging points to capture the event logs. \par For objective L3, the quality of the logs is essential for log analysis. This objective ensures that the captured event logs are complete, accurate, and available when the logs are extracted by the log analysis tool. The method requirements were defined to adhere to the log quality specification\par For objective L4, maintenance prioritisation is determined. The calculations needed for this log analysis are explained for this objective that needs to be executed in the log analysis. Prioritisation of each subsystem will be calculated in the specified time frame. For this objective, the requirements for which logs to use are also defined, as some types of user activity can be excluded based on the software system used.\par Empirical objectives use the method in a test system to verify the results and implement it in case studies. It also reflects on the study methodology using the results to determine whether this solution has resolved the problem statement.\par For objective E1, the following sub-objectives are met for the implementation of the method on the test system:

		\begin{enumerate}
			\item The user activity types and log attributes for the test system were defined. A logging point(s) was placed on the client or server side for the test system.
			\item This strategic placement of the logging point(s) was determined by what log attributes need to be obtained in certain stages of the software system's logging mechanism, structure, and complexity. The logging points store the event logs in a structured database.
			\item A log analysis tool is created or a suitable third-party tool is used to analyse the extracted logs. Log quality is also checked in this objective to determine if logs are in an acceptable standard set by the requirements in L3. 
			\item Maintenance prioritisation is calculated for each subsystem for this sub-objective using L4.
		\end{enumerate} 

		For objective E2, the results of the implementation of the method in the test system are verified in this objective. Objectives L1, L2, L3 and L4 verified if the method can create software maintenance prioritisations for the test system by comparing it to the expected results. \par For objective E3, the verified method of E1 is applied to multiple case studies and the results are evaluated. A critical analysis of the case studies is performed to validate the software maintenance prioritisation for this study with the results of the case studies. With this validation strategy, this study is validated that it meets the study objectives with the created solution for the original problem statement.

\item \textbf{Reflection on methodology} \par In \Cref{chap:2} the development of the functional requirements of the solution is made in \Cref{sec:ch2_developementOfSolution}. This provides a generic method to create a logging mechanism and analyse the obtained user-based logs. A test logging mechanism is designed with a log analysis of usage to validate the development of functional requirements for the solution of \Cref{tbl:ch2_developmenetRequirements}.\par This logging mechanism aims to implement each sub-functional requirement in a test system by testing certain inputs to verify expected outputs. The following validation method was used for this test implementation in \Cref{sec:ch3_implementation}:
	\begin{itemize}
		\item Identifying and creating the log attributes needed for the log analysis (\ref{fr:logAttributes}). The software system's key log attributes are precisely defined for maintenance prioritisation. The user-activity type forms the base requirement for a user-based log.
		
		\item Logging points are made to capture these logging attributes at specific locations in the software system (\ref{fr:loggingPoints}). The placement of the logging points to capture user-based logs is verified if it can be done consistently, accurately, and discretely without impacting the software system's performance. 
		
		\item Log analysis is verified using a third-party log analysis tool or the implementation of a log analysis (\ref{fr:logAnalysis}). For the log analysis to be successful, the quality must be acceptable. This is verified by the logging points' performance and the usability of the logs without too many post-logging corrections made.
		
		\item Creating software maintenance prioritising (\ref{fr:maintenancePrioritising}) from the results of log analysis. In the log analysis, the different subsystems' maintenance priority ($M_{PF}$) are calculated from the normalised total active users ($P_N$) multiplied by the normalised total user activity ($A_N$) for a specified subsystem in \Cref{eq:ch2_priorityNormalised,eq:ch2_maintenanceFactorSimplified,eq:ch2_eventNormalised}.\par These results are verified with the test case study and Case Studies A, B, and C in \Cref{sec:ch3_caseStudies} on different software systems with different operational use cases. The results obtained for the maintenance priority validate the implementation of the previous one using the defined user-based logs to perform the log analysis for the maintenance priority. 
	\end{itemize}

\item \textbf{Conclusion} \par For this study the following outcomes are presented on how the solution has been presented to solve the original problem statement:
	\begin{itemize}
		\item The solution in this study aims to prioritise software maintenance by using event logging and log analysis.
		\item The results of this study showed that the solution could create a logging mechanism for prioritisation of software maintenance, as stipulated in the study objectives of \Cref{tbl:ch4_ValidationStart}.
		\item Therefore, the need to develop a method to be able to do log analysis for software maintenance by creating a suitable logging mechanism to capture user-based event logs has been addressed by the study objectives.
		\item The original problem statement defined in \Cref{sec:ch1_problemStatement} has been successfully addressed by the study objectives.
		\item Finally, the identified gap has been addressed and fulfilled by providing a solution to the original problem statement.
	\end{itemize}
\end{enumerate}

\section{Recommendations}
In \Cref{sec:ch3_caseStudies}, the case studies highlighted the limitations of the method. 

\subsection{Logging quality}
\Cref{sec:ch1_loggingQuality} describes the quality of the event log as an essential part of the logging mechanism. Event logs must be accurate, manage complex structures, and be consistent and complete. For the methodology used, not all dimensions of \Cref{fig:ch1_EventQModel} are used to design the logging mechanism.\par This presents the functional requirement of Case Study B's logging points (\ref{fr:loggingPoints}). The multiple logging points introduced inconsistencies in the event logs for the groups of subsystems used. There are studies on improving event log quality, but creating an event log quality model specifically for user-based event logging can increase log quality. \par Some of the defined event log quality model requirements specified in \Cref{fig:ch1_EventQModel} still need to be fully integrated into the method. Some of these requirements can add value to log quality.

\subsection{Maintenance prioritisation}
The maintenance prioritisation (\ref{fr:maintenancePrioritising}) can have improvements made in multiple ways. \Cref{eq:ch2_maintenanceFactorSimplified,eq:ch2_eventNormalised,eq:ch2_priorityNormalised} uses the full user-based event logs per subsystem and the total users linked per system as its base variables\par From the results observed in the case studies in \Cref{sec:ch3_caseStudies}, the base variables had an overwhelming impact on the prioritisation factor. Introducing other variables that represent other factors from the log attributes can improve the accuracy of maintenance prioritisation. An important variable that could have been used is the type of user activity of each case study.

\subsubsection{User activity types}
Throughout the study, the type of user activity was essential to describe what can be classified as a user event. This primary log attribute can add another dimension to the results, as some user activities may be more important than others. \par For software systems, as in Case Study C, where most types of user activity were grouped, the final results can be beneficial. There are some differences between some activity types. 

\subsubsection{User and activity parameters}
\par Normalisation is used in \Cref{eq:ch2_maintenanceFactorSimplified,eq:ch2_eventNormalised,eq:ch2_priorityNormalised} to make a comparable scale for both main variables for software maintenance prioritisation. While normalisation yielded similar results, there were numerous outliers on each variable's low and high ends. The data do not follow a specific distribution or pattern as $S_{582}$ of Case Study A with a normalised activity of 1. This subsystem had the highest normalised activity but had the $4^{th}$ highest maintenance priority due to its lower unique active user base.\par Using different techniques to formulate a software maintenance priority factor may have placed $S_{582}$ higher. If the effect of total unique users was not used as the primary prioritisation factor for this situation. 

\subsubsection{Use of other classification strategies}
Normalisation was used for maintenance priority calculations. Using other statistical methods can yield improved prioritisation. Only one prioritisation method was used. There is a need to enhance prioritisation by comparing different prioritisation methods.

\section{Conclusion}

\subsection{In summary}
\begin{itemize}
	\item There is a need to improve software maintenance activities in the industry, but software maintenance prioritisation is still a problem for most software developers.
	\item Event-based logging is a proven method to get valuable information about a software system.
	\item A log analysis of the utilisation of the software system can provide the needed evidence to prioritise software systems based on the extracted log data.
	\item Creating a user-based event logging mechanism to implement a system utilisation log analysis solves the identified problem.
	\item Three different case studies with two other operational use cases verified the methodology designed for this study.
\end{itemize}

\subsection{In conclusion}
Analysing user-based event logs can improve software maintenance resource management by prioritising maintenance tasks through a comprehensive log analysis.