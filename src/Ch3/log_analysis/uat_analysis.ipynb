{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../../Chapters/tables/'\n",
    "color_pallette = 'deep' #muted deep bright pastel dark colorblind\n",
    "\n",
    "def getSystemPriority():\n",
    "    clients = pd.read_csv(\"../data/uat_raw/clientUsers.csv\")\n",
    "    employees = pd.read_csv(\"../data/uat_raw/employeUsers.csv\")\n",
    "\n",
    "    # Merge the two dataframes based on matching SubSystemId values\n",
    "    merged_df = pd.merge(clients, employees, on='SubSystemId', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Replace any NaN values with 0\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate TotalUserCount where UserCount values are equal\n",
    "    merged_df['TotalUserCount'] = merged_df.apply(lambda row: row['UserCount_df1'] + row['UserCount_df2'], axis=1)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def getBaseProjectDataC():\n",
    "    \"\"\"\n",
    "    Gets the base data for the project\n",
    "\n",
    "    Returns:\n",
    "    A dataframe with user activities\n",
    "    \"\"\"\n",
    "    projectBaseData = pd.DataFrame()  # Initialize an empty dataframe\n",
    "\n",
    "    for i in range(2, 9):  # Loop over file names \"uat2\" to \"uat8\"\n",
    "        filename = f\"../data/uat_raw/uat{i}.csv\"\n",
    "        data = pd.read_csv(filename)\n",
    "        projectBaseData = pd.concat([projectBaseData, data], ignore_index=True) \n",
    "\n",
    "    systemsData = pd.read_csv(\"../data/uat_raw/unique_systems.csv\")\n",
    "    users = pd.read_csv(\"../data/uat_raw/users.csv\")\n",
    "    temp = pd.merge(systemsData, projectBaseData, on='Controller')\n",
    "    temp = pd.merge(users, temp, on='UserId')\n",
    "\n",
    "    # Calculate Priority based on total users linked to a subsystem\n",
    "    subsystem_users = temp.groupby('SubSystemId')['UserId'].nunique()\n",
    "    temp['TotalUserCount'] = temp['SubSystemId'].map(subsystem_users)\n",
    "    selected_activities = [\"SpanClicked\", \"ButtonClicked\", \"DivClicked\", \"HyperLinkClicked\",\n",
    "     \"ListClicked\", \"LabelClicked\", \"ImageClicked\", \"FormInput\", \"SelectClicked\"]\n",
    "\n",
    "    temp.loc[temp['ActivityType'].isin(selected_activities), 'ActivityType'] = 'HTMLElement'\n",
    "\n",
    "    custom_activities = [\"GridItem\"]\n",
    "    temp.loc[temp['ActivityType'].isin(custom_activities), 'ActivityType'] = 'CustomControls'\n",
    "    return temp\n",
    "\n",
    "def getBaseProjectData(file):\n",
    "    \"\"\"\n",
    "    Gets the base data for the project\n",
    "\n",
    "    Returns:\n",
    "    A dataframe with user activities\n",
    "    \"\"\"\n",
    "    systemsData = pd.read_csv(\"../data/uat_raw/systems.csv\")\n",
    "    projectBaseData = pd.read_csv(f\"../data/uat_raw/{file}.csv\")\n",
    "    priority = getSystemPriority()\n",
    "    users = pd.read_csv(\"../data/uat_raw/users.csv\")\n",
    "\n",
    "    temp = pd.merge(systemsData, projectBaseData,on='SubSystemId')\n",
    "    temp = pd.merge(users, temp, on='UserId')\n",
    "    temp = pd.merge(priority, temp, on='SubSystemId')\n",
    "\n",
    "    return temp.loc[(temp['Project'] == 1) & (temp['Deleted'] == 1)], temp.loc[(temp['Project'] == 2) & (temp['Deleted'] == 1)];\n",
    "\n",
    "def getNormalisedByTotal(data):\n",
    "    temp = data.groupby(['SubSystemId']).agg(\n",
    "        TotalUserCount=('TotalUserCount', 'mean'),\n",
    "        Count=('SubSystemId', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Normalize TotalUserCount\n",
    "    min_total_user_count = temp['TotalUserCount'].min()\n",
    "    max_total_user_count = temp['TotalUserCount'].max()\n",
    "    temp['Priority'] = (temp['TotalUserCount'] - min_total_user_count) / (max_total_user_count - min_total_user_count)\n",
    "\n",
    "    # Normalize Count\n",
    "    min_count = temp['Count'].min()\n",
    "    max_count = temp['Count'].max()\n",
    "    temp['NormalisedCount'] = (temp['Count'] - min_count) / (max_count - min_count)\n",
    "\n",
    "    # Calculate MaintenanceFactor\n",
    "    temp['MaintenanceFactor'] = temp['NormalisedCount'] * temp['Priority']\n",
    "\n",
    "    return temp\n",
    "\n",
    "def getNormilisedBySecondCriteria(data, secondFilter):\n",
    "    temp = data.groupby(['SubSystemId',secondFilter]).agg(TotalUserCount=('TotalUserCount', 'mean'),\n",
    "     Count=('SubSystemId', 'count')).reset_index()\n",
    "\n",
    "    min_count = temp['TotalUserCount'].min()\n",
    "    max_count = temp['TotalUserCount'].max()\n",
    "\n",
    "    temp['Priority'] = temp['TotalUserCount'].apply(lambda x: \n",
    "        (x-min_count)/(max_count-min_count))\n",
    "\n",
    "    # get the number of unique entries in the 'ActivityType' column\n",
    "    num_activity_types = data[secondFilter].nunique()\n",
    "\n",
    "    # get the first 'Priority' value for each 'SubSystemId'\n",
    "    first_priority = temp.groupby('SubSystemId')['Priority'].first()\n",
    "\n",
    "    # pivot the table and merge with the first priority values\n",
    "    pivoted_df = temp.pivot_table(index='SubSystemId', columns=secondFilter, values='Count', fill_value=0)\n",
    "    pivoted_df = pivoted_df.merge(first_priority, left_index=True, right_index=True).reset_index()\n",
    "\n",
    "    # get all unique entries in the 'x' column\n",
    "    unique_values = data[secondFilter].unique()\n",
    "\n",
    "    for name in unique_values:\n",
    "        normalised_table_name = f'NormalisedCount_{name}'\n",
    "        maintenance_table_name = f'MaintenanceFactor_{name}'\n",
    "        pivoted_min = pivoted_df[name].min()\n",
    "        pivoted_max = pivoted_df[name].max()\n",
    "\n",
    "        # calculate the normalized count\n",
    "        pivoted_df[normalised_table_name] = (pivoted_df[name] - pivoted_min) / (pivoted_max - pivoted_min)\n",
    "\n",
    "        # calculate the maintenance factor\n",
    "        pivoted_df[maintenance_table_name] = pivoted_df[normalised_table_name] * pivoted_df['Priority']\n",
    "\n",
    "    return pivoted_df\n",
    "\n",
    "def mergedColumns(data, secondFilter):\n",
    "    temp = getNormalisedByTotal(data)\n",
    "    temp2 = getNormilisedBySecondCriteria(data, secondFilter)\n",
    "    columns_to_keep = data['ActivityType'].unique().tolist()\n",
    "    columns_to_keep.append('SubSystemId')\n",
    "\n",
    "    merged_df = pd.merge(temp, temp2[columns_to_keep], on='SubSystemId')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project actvities\n",
    "projectB, projectA = getBaseProjectData('uat1')\n",
    "projectC = getBaseProjectDataC()\n",
    "\n",
    "# Get project total activities per project\n",
    "projectA_Normilised = mergedColumns(projectA, 'ActivityType')\n",
    "projectB_Normilised = mergedColumns(projectB, 'ActivityType')\n",
    "projectC_Normilised = mergedColumns(projectC, 'ActivityType')\n",
    "\n",
    "# Test data\n",
    "testA, testB = getBaseProjectData('test_data')\n",
    "\n",
    "# Get project total activities per project\n",
    "testB_Normilised = getNormalisedByTotal(testB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLatexRows(data, filename, caption, testData, fullData = True):\n",
    "    data = data.sort_values(by='MaintenanceFactor', ascending=False)\n",
    "\n",
    "    # select the top 25 entries\n",
    "    #data = data.head(40)\n",
    "\n",
    "    #data = data.sort_values(by='SubSystemId', ascending=True)\n",
    "    data['rank'] = data['MaintenanceFactor'].rank(method='min', ascending=False)\n",
    "\n",
    "    latex_rows = ''\n",
    "    index_row = 1\n",
    "    for index, row in data.iterrows():\n",
    "        systemId = f\"$S_{index+1}$\" if testData else f\"$S_{{{int(row['SubSystemId'])}}}$\"\n",
    "        row_text = \"\\\\rowcolor{lightgray}\" if index_row % 2 != 0 else \"\"\n",
    "        index_row += 1\n",
    "\n",
    "        if fullData:\n",
    "            latex_rows += '\\n {:s} {:s} & {:d} & {:.4f} & {:d} & {:.4f} & {:.4f} & {:d} \\\\\\ '.format(row_text, systemId, int(row['TotalUserCount']) ,row['Priority'], int(row['Count']), row['NormalisedCount'], row['MaintenanceFactor'], int(row['rank']))\n",
    "        else:\n",
    "            latex_rows += '\\n {:s} {:s} & {:.4f} & {:.4f} & {:.4f} & {:d} \\\\\\ '.format(row_text, systemId, row['Priority'], row['NormalisedCount'], row['MaintenanceFactor'], int(row['rank']))\n",
    "\n",
    "    columns = \"XPPPPPP\" if fullData else \"XPPPP\"\n",
    "    column_names = r\"\"\"\\thead{$S_{X}$} & \\thead{$P_X$} & \\thead{$P_N$}  & \\thead{$A_X$} & \\thead{$A_N$} & \\thead{$M_{PF}$} & \\thead{$P_{R}$} \\\\\"\"\" if fullData else r\"\"\"\\thead{$S_{X}$} & \\thead{$P_N$}  & \\thead{$A_N$} & \\thead{$M_{PF}$} & \\thead{$P_{R}$} \\\\\"\"\"\n",
    "\n",
    "    column_amount = \"7\" if fullData else \"5\"\n",
    "\n",
    "    header = r\"\"\"\n",
    "    \\begin{xltabular}{\\textwidth}{%s}\n",
    "        \\caption[%s]\n",
    "        {\\textit{%s}}\n",
    "        \\label{tbl:apx_%s} \\\\\n",
    "        \\toprule\n",
    "         %s\n",
    "        \\midrule\n",
    "        \\endfirsthead\n",
    "\n",
    "        \\caption[]{\\continueCaption} \\\\\n",
    "        \\toprule\n",
    "        %s\n",
    "        \\midrule\n",
    "        \\endhead\n",
    "\n",
    "        \\midrule\n",
    "        \\multicolumn{%s}{r}{\\continueText} \\\\ \n",
    "        \\endfoot\n",
    "        \\endlastfoot\n",
    "    \"\"\" % (columns, caption, caption, filename, column_names, column_names, column_amount) \n",
    "    \n",
    "    table = header + latex_rows.strip() + r\"\"\"\n",
    "        \\bottomrule\n",
    "    \\end{xltabular}\n",
    "    \"\"\"\n",
    "\n",
    "    filepath = directory + filename + '.tex'\n",
    "\n",
    "    # Write the latex_rows string to the file\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(table)\n",
    "\n",
    "\n",
    "createLatexRows(projectA_Normilised, \"projectA_Normilised\", \"Case study A results\", False)\n",
    "createLatexRows(projectB_Normilised, \"projectB_Normilised\", \"Case study B results\", False)\n",
    "createLatexRows(projectC_Normilised, \"projectC_Normilised\", \"Case study C results\", False)\n",
    "\n",
    "# Test data \n",
    "createLatexRows(testB_Normilised, \"testB_Normilised\", \"Test data\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFigures(data, case, stackedColumns):\n",
    "    # Sort the dataframe by the 'Count' column in descending order\n",
    "    #data = data.sort_values(by='Count', ascending=False)\n",
    "\n",
    "    # Select the top 40 entries\n",
    "    # Calculate the quartiles\n",
    "    q1 = data['Count'].quantile(0.25)\n",
    "    q3 = data['Count'].quantile(0.75)\n",
    "\n",
    "    # Filter the data based on the quartiles\n",
    "    filtered_data = data[(data['Count'] >= q3)]\n",
    "\n",
    "    # Sort the dataframe by the 'SubSystemId' column\n",
    "    filtered_data = filtered_data.sort_values(by='SubSystemId')\n",
    "\n",
    "    # Create latex table\n",
    "    table_name = f\"case{case}\"\n",
    "    table_heading = f\"Case study {case}'s upper quartile maintenance performance\"\n",
    "    createLatexRows(filtered_data, table_name, table_heading, False, False)\n",
    "\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "\n",
    "    # Get the unique SubSystemIds\n",
    "    subsystem_ids = filtered_data['SubSystemId'].unique()\n",
    "\n",
    "    # Set the number of subsystems to show per graph\n",
    "    num_subsystems_per_graph = 300\n",
    "\n",
    "    # Calculate the number of graphs needed\n",
    "    num_graphs = int(np.ceil(len(subsystem_ids) / num_subsystems_per_graph))\n",
    "\n",
    "    filtered_data['SS_SystemId'] = '$S_{' + filtered_data['SubSystemId'].astype(str) + '}$'\n",
    "\n",
    "    # Define a software color palette\n",
    "    colors = sns.color_palette(color_pallette, n_colors=len(stackedColumns))\n",
    "\n",
    "    # Loop through each graph\n",
    "    for i in range(num_graphs):\n",
    "        start_index = i * num_subsystems_per_graph\n",
    "        end_index = min((i + 1) * num_subsystems_per_graph, len(subsystem_ids))\n",
    "        current_ids = subsystem_ids[start_index:end_index]\n",
    "\n",
    "        # Filter the data to show only the current subsystem ids\n",
    "        current_data = filtered_data[filtered_data['SubSystemId'].isin(current_ids)]\n",
    "\n",
    "        # Create figure and axis objects with subplots()\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # Plot the stacked bar chart\n",
    "        current_data.plot(kind='bar', x='SS_SystemId', y=stackedColumns, stacked=True, ax=ax, color=colors)\n",
    "\n",
    "        ax.set_ylabel('User activities')\n",
    "\n",
    "        # Set the x-axis label and tick label rotation\n",
    "        ax.set_xlabel(r'Subsystem $S_X$')\n",
    "        plt.xticks(rotation='45', ha='right')\n",
    "\n",
    "        # Add a legend\n",
    "        ax.legend()\n",
    "\n",
    "        # Add a title to the chart\n",
    "        plt.title(f'Subsystem vs. user activities per user activity type')\n",
    "\n",
    "        # Save the current figure\n",
    "        plt.savefig(f'../../../img/ch3/analysis/case_{case}_subsystems_{i + 1}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "        # Close the figure to free memory\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "createFigures(projectA_Normilised, 'A', projectA['ActivityType'].unique().tolist())\n",
    "createFigures(projectB_Normilised, 'B', projectB['ActivityType'].unique().tolist())\n",
    "createFigures(projectC_Normilised, 'C', projectC['ActivityType'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uatBreakdown(data, label):\n",
    "    # Count the occurrences of each category\n",
    "    category_counts = data['ActivityType'].value_counts()\n",
    "\n",
    "    # Define Seaborn color palette to use\n",
    "    colors = sns.color_palette(color_pallette, n_colors=len(category_counts))\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Plotting a pie chart\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "    plt.pie(category_counts, colors=colors)\n",
    "    plt.axis('equal')  # Ensure that pie is drawn as a circle\n",
    "    # plt.title('User activity breakdown for System ' + label)\n",
    "\n",
    "    # Create a custom legend with percentages\n",
    "    legend_labels = [f'{label}: {count} ({(count/len(data)*100):.1f}%)' for label, count in category_counts.items()]\n",
    "\n",
    "    # Add the legend\n",
    "    plt.legend(legend_labels)\n",
    "\n",
    "    # Save the current figure\n",
    "    plt.savefig(f'../../../img/ch3/analysis/case_{label}_breakdown.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "uatBreakdown(projectA, 'A')\n",
    "uatBreakdown(projectB, 'B')\n",
    "uatBreakdown(projectC, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Controller' column to string data type\n",
    "projectC['Controller'] = projectC['Controller'].astype(str)\n",
    "\n",
    "unique_controllers = projectC['Controller'].unique().tolist()\n",
    "\n",
    "# Sort the unique controllers alphabetically\n",
    "unique_controllers_sorted = sorted(unique_controllers)\n",
    "\n",
    "# Create a new DataFrame with the sorted unique controllers\n",
    "unique_controllers_df = pd.DataFrame({'Unique Controllers': unique_controllers_sorted})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "unique_controllers_df.to_csv('../data/uat_raw/unique_controllers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
